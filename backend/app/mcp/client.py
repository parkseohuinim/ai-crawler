"""
MCP í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„
ë°±ì—”ë“œì—ì„œ MCP ë„êµ¬ì™€ ì§ì ‘ í†µì‹ í•˜ê¸° ìœ„í•œ í´ë¼ì´ì–¸íŠ¸
"""

import asyncio
import logging
import json
import os
import sys
from typing import Dict, Any, Optional, List

logger = logging.getLogger(__name__)

# MCP ì„œë²„ ë„êµ¬ë“¤ ì§ì ‘ ì„í¬íŠ¸
try:
    # mcp-server ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
    current_dir = os.path.dirname(os.path.abspath(__file__))
    backend_dir = os.path.dirname(os.path.dirname(current_dir))  # ai-crawler/backend
    project_root = os.path.dirname(backend_dir)  # ai-crawler
    mcp_server_dir = os.path.join(project_root, "mcp-server")
    
    if mcp_server_dir not in sys.path:
        sys.path.insert(0, mcp_server_dir)
    
    from tools.site_analyzer import SiteAnalyzer
    from tools.crawler_selector import CrawlerSelector  
    from tools.structure_detector import StructureDetector
    from tools.quality_validator import QualityValidator
    
    logger.info("ğŸ”§ MCP ë„êµ¬ë“¤ ì§ì ‘ ì„í¬íŠ¸ ì„±ê³µ")
    
except ImportError as e:
    logger.error(f"âŒ MCP ë„êµ¬ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    raise

class MCPClient:
    """MCP ë„êµ¬ì™€ ì§ì ‘ í†µì‹ í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self):
        """MCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” - ë„êµ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        try:
            self.site_analyzer = SiteAnalyzer()
            self.crawler_selector = CrawlerSelector()
            self.structure_detector = StructureDetector()
            self.quality_validator = QualityValidator()
            
            logger.info("âœ… MCP ë„êµ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ MCP ë„êµ¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
        
    def connect(self):
        """ì—°ê²° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € (í˜¸í™˜ì„±ì„ ìœ„í•œ ë”ë¯¸)"""
        class DummyAsyncContext:
            def __init__(self, client):
                self.client = client
            
            async def __aenter__(self):
                return self.client
            
            async def __aexit__(self, exc_type, exc_val, exc_tb):
                pass
        
        return DummyAsyncContext(self)
    
    async def analyze_site(self, url: str, sample_html: str = "", headers: Dict[str, Any] = None) -> Dict[str, Any]:
        """ì‚¬ì´íŠ¸ ë¶„ì„ ë° í¬ë¡¤ëŸ¬ ì„ íƒ"""
        if headers is None:
            headers = {}
            
        try:
            logger.info(f"ğŸ” ì‚¬ì´íŠ¸ ë¶„ì„ ì‹œì‘: {url}")
            result = await self.site_analyzer.analyze_and_select(
                url=url,
                sample_html=sample_html,
                headers=headers
            )
            logger.info("âœ… ì‚¬ì´íŠ¸ ë¶„ì„ ì™„ë£Œ")
            return result
        except Exception as e:
            logger.error(f"âŒ ì‚¬ì´íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "error": str(e),
                "url": url,
                "status": "failed"
            }
    
    async def detect_structure(self, html_sample: str, url: str = "") -> Dict[str, Any]:
        """ì½˜í…ì¸  êµ¬ì¡° ë¶„ì„"""
        try:
            logger.info(f"ğŸ” êµ¬ì¡° ë¶„ì„ ì‹œì‘: {url}")
            result = await self.structure_detector.detect_structure(
                html_sample=html_sample,
                url=url
            )
            logger.info("âœ… êµ¬ì¡° ë¶„ì„ ì™„ë£Œ")
            return result
        except Exception as e:
            logger.error(f"âŒ êµ¬ì¡° ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "error": str(e),
                "url": url,
                "status": "failed"
            }
    
    async def generate_strategy(self, site_analysis: Dict[str, Any], content_structure: Dict[str, Any]) -> Dict[str, Any]:
        """í¬ë¡¤ë§ ì „ëµ ìƒì„±"""
        try:
            logger.info("ğŸ” ì „ëµ ìƒì„± ì‹œì‘")
            result = await self.crawler_selector.generate_strategy(
                site_analysis=site_analysis,
                content_structure=content_structure
            )
            logger.info("âœ… ì „ëµ ìƒì„± ì™„ë£Œ")
            return result
        except Exception as e:
            logger.error(f"âŒ ì „ëµ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "error": str(e),
                "status": "failed"
            }
    
    async def validate_result(self, extracted_data: Dict[str, Any], url: str, expected_quality: float = 70.0) -> Dict[str, Any]:
        """í¬ë¡¤ë§ ê²°ê³¼ ê²€ì¦"""
        try:
            logger.info(f"ğŸ” í’ˆì§ˆ ê²€ì¦ ì‹œì‘: {url}")
            result = await self.quality_validator.validate_result(
                extracted_data=extracted_data,
                url=url,
                expected_quality=expected_quality
            )
            logger.info("âœ… í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ")
            return result
        except Exception as e:
            logger.error(f"âŒ í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return {
                "error": str(e),
                "url": url,
                "status": "failed"
            }
    
    async def extract_selective_content(self, html_content: str, target_content: str, url: str = "") -> Dict[str, Any]:
        """ì„ íƒì  ì½˜í…ì¸  ì¶”ì¶œ"""
        try:
            logger.info(f"ğŸ¯ ì„ íƒì  ì¶”ì¶œ ì‹œì‘: {target_content} from {url}")
            
            # content_extractorê°€ ì—†ëŠ” ê²½ìš° ì„í¬íŠ¸ ì‹œë„
            if not hasattr(self, 'content_extractor'):
                from tools.content_extractor import ContentExtractor
                self.content_extractor = ContentExtractor()
            
            result = await self.content_extractor.extract_selective_content(
                html_content=html_content,
                target_content=target_content,
                url=url
            )
            logger.info("âœ… ì„ íƒì  ì¶”ì¶œ ì™„ë£Œ")
            return result
        except Exception as e:
            logger.error(f"âŒ ì„ íƒì  ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {
                "error": str(e),
                "target_content": target_content,
                "url": url,
                "status": "failed"
            } 