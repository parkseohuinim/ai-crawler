import re
from typing import Dict, Any, Optional
from ..crawlers.base import CrawlResult
from datetime import datetime

def clean_crawled_text(text: str) -> str:
    """
    í¬ë¡¤ë§ëœ í…ìŠ¤íŠ¸ì—ì„œ ë¶ˆí•„ìš”í•œ ìš”ì†Œë“¤ì„ ì œê±°í•˜ê³  ê°€ë…ì„±ì„ ê°œì„ í•©ë‹ˆë‹¤.
    
    Args:
        text: ì›ë³¸ í¬ë¡¤ë§ëœ í…ìŠ¤íŠ¸
        
    Returns:
        ì •ì œëœ í…ìŠ¤íŠ¸
    """
    if not text or not isinstance(text, str):
        return ""
    
    # 1. ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì ì •ë¦¬ (ë” ê°•ë ¥í•˜ê²Œ)
    cleaned = text.replace('\\n', '\n').replace('\\t', '\t').replace('\\"', '"').replace("\\'", "'")
    cleaned = re.sub(r'\\([()])', r'\1', cleaned)  # \( \) ê°™ì€ ë°±ìŠ¬ë˜ì‹œ ì´ìŠ¤ì¼€ì´í•‘ ì œê±°
    
    # 2. JavaScript ë§í¬ ë° ë¶ˆí•„ìš”í•œ ë§í¬ ì œê±°
    # [í…ìŠ¤íŠ¸](javascript:...) í˜•íƒœì˜ ë§í¬ë¥¼ í…ìŠ¤íŠ¸ë§Œ ë‚¨ê¸°ë„ë¡ ë³€ê²½ (ì¤‘ì²© ê´„í˜¸ ì²˜ë¦¬)
    cleaned = re.sub(r'\[([^\]]+)\]\(javascript:[^)]*(?:\([^)]*\))*[^)]*\)', r'\1', cleaned)
    # [í…ìŠ¤íŠ¸](#...) í˜•íƒœì˜ ì•µì»¤ ë§í¬ë„ í…ìŠ¤íŠ¸ë§Œ ë‚¨ê¹€
    cleaned = re.sub(r'\[([^\]]+)\]\(#[^)]*\)', r'\1', cleaned)
    # mailto: ë§í¬ë„ ì œê±°
    cleaned = re.sub(r'\[([^\]]+)\]\(mailto:[^)]*\)', r'\1', cleaned)
    # HTTP/HTTPS ë§í¬ëŠ” ìœ ì§€í•˜ë˜, ê¸´ ë§í¬ëŠ” ë„ë©”ì¸ë§Œ í‘œì‹œ
    cleaned = re.sub(r'\[([^\]]+)\]\((https?://[^/)]+)/[^)]*\)', r'\1 (\2)', cleaned)
    
    # 3. UI ìš”ì†Œ ì œê±° (ë” í¬ê´„ì ìœ¼ë¡œ)
    ui_patterns = [
        r'_[^_]*ì•„ì´ì½˜_',  # _ì•„ì´ì½˜_ íŒ¨í„´
        r'_[^_]*ë²„íŠ¼_',   # _ë²„íŠ¼_ íŒ¨í„´
        r'_[^_]*ë§í¬_',   # _ë§í¬_ íŒ¨í„´
        r'ë¡œê·¸ì¸ì „\s*ì•„ì´ì½˜\s*',
        r'\s*ë°”ë¡œê°€ê¸°\s*$',  # ë°”ë¡œê°€ê¸° (ì•ë’¤ ê³µë°± í¬í•¨)
        r'\s*ë”ë³´ê¸°\s*$',    # ë”ë³´ê¸° (ì•ë’¤ ê³µë°± í¬í•¨)
        r'ê²€ìƒ‰\s*$',        # ì¤„ ëì˜ 'ê²€ìƒ‰'
        r'ë¡œê·¸ì¸\s*$',      # ì¤„ ëì˜ 'ë¡œê·¸ì¸'
        r'ë³¸ë¬¸\s*ë°”ë¡œê°€ê¸°.*?ë°”ë¡œ\s*ê°€ê¸°',  # ì ‘ê·¼ì„± ë§í¬ë“¤
        r'\s*ìƒˆì°½ì—´ë¦¼\s*',  # "ìƒˆì°½ì—´ë¦¼" í…ìŠ¤íŠ¸
        r'\s*í¼ì¹˜ê¸°\s*',    # "í¼ì¹˜ê¸°" í…ìŠ¤íŠ¸
        r'"[^"]*ìƒˆì°½ì—´ë¦¼[^"]*"',  # ìƒˆì°½ì—´ë¦¼ ê´€ë ¨ í…ìŠ¤íŠ¸
        r'"[^"]*í¼ì¹˜ê¸°[^"]*"',   # í¼ì¹˜ê¸° ê´€ë ¨ í…ìŠ¤íŠ¸
    ]
    
    for pattern in ui_patterns:
        cleaned = re.sub(pattern, '', cleaned, flags=re.MULTILINE | re.IGNORECASE)
    
    # 3. ë§ˆí¬ë‹¤ìš´ ë° êµ¬ë¶„ì„  ì •ë¦¬ (ë” ì² ì €í•˜ê²Œ)
    # ì—°ì†ëœ í—¤ë” ë§ˆí¬ë‹¤ìš´ ì •ë¦¬
    cleaned = re.sub(r'#{4,}', '###', cleaned)
    
    # ë¶ˆí•„ìš”í•œ êµ¬ë¶„ì„  ì œê±° (ë‹¤ì–‘í•œ íŒ¨í„´)
    cleaned = re.sub(r'^[\*\-_]{3,}\s*$', '', cleaned, flags=re.MULTILINE)
    cleaned = re.sub(r'^\*\s*\*\s*\*\s*$', '', cleaned, flags=re.MULTILINE)
    
    # 4. ë¦¬ìŠ¤íŠ¸ í˜•ì‹ í†µì¼ (* ë¥¼ - ë¡œ ë³€ê²½í•˜ì—¬ ì¼ê´€ì„± í™•ë³´)
    cleaned = re.sub(r'^(\s*)\*\s+', r'\1- ', cleaned, flags=re.MULTILINE)
    
    # 5. ë¶ˆí•„ìš”í•œ ê³µë°±ê³¼ ê°œí–‰ ì •ë¦¬
    # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ
    cleaned = re.sub(r' {2,}', ' ', cleaned)
    
    # ì¤„ ë ê³µë°± ì œê±°
    cleaned = re.sub(r' +$', '', cleaned, flags=re.MULTILINE)
    
    # ì—°ì†ëœ ê°œí–‰ì„ ìµœëŒ€ 2ê°œë¡œ ì œí•œ
    cleaned = re.sub(r'\n{3,}', '\n\n', cleaned)
    
    # 6. ë¬¸ì¥ êµ¬ì¡° ê°œì„ 
    lines = cleaned.split('\n')
    improved_lines = []
    
    for line in lines:
        line = line.strip()
        if not line:
            improved_lines.append('')
            continue
            
        # ì˜ë¯¸ì—†ëŠ” ë‹¨ë… ë¬¸ì ì œê±°
        if len(line) == 1 and line in '#*-_':
            continue
            
        # ë„ˆë¬´ ì§§ì€ ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œ ì œê±°
        if line.startswith('* ') and len(line) < 5:
            continue
            
        # í•´ì‹œíƒœê·¸ íŒ¨í„´ ì •ë¦¬ (# ì¸í„°ë„· ì ‘ì†ë¶ˆê°€# TV ë¦¬ëª¨ì»¨ -> # ì¸í„°ë„· ì ‘ì†ë¶ˆê°€ # TV ë¦¬ëª¨ì»¨)
        if '#' in line and not line.startswith('#'):
            line = re.sub(r'#\s*([^#]+?)#', r'# \1 #', line)
            line = re.sub(r'#\s*([^#]+?)$', r'# \1', line)
        
        improved_lines.append(line)
    
    # 7. ìµœì¢… ì •ë¦¬
    result = '\n'.join(improved_lines)
    
    # ì‹œì‘ê³¼ ëì˜ ê³µë°± ì œê±°
    result = result.strip()
    
    # ì—°ì†ëœ ë¹ˆ ì¤„ ìµœì¢… ì •ë¦¬
    result = re.sub(r'\n{3,}', '\n\n', result)
    
    return result

def extract_main_content(text: str) -> str:
    """
    í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” ì»¨í…ì¸ ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ë„¤ë¹„ê²Œì´ì…˜, í‘¸í„°, ì‚¬ì´ë“œë°” ë“±ì„ ì œê±°í•˜ê³  ë³¸ë¬¸ ë‚´ìš©ë§Œ ë‚¨ê¹ë‹ˆë‹¤.
    
    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸
        
    Returns:
        ì£¼ìš” ì»¨í…ì¸ ë§Œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸
    """
    if not text:
        return ""
    
    # ğŸ”§ ì‹¤ì œ ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ë„ë¡ ìˆ˜ì •
    cleaned = text
    
    # 1. ëŒ€ê·œëª¨ ë¶ˆí•„ìš” ì„¹ì…˜ ì œê±°
    # ì „ì²´ ë„¤ë¹„ê²Œì´ì…˜ ë©”ë‰´ ë¸”ë¡ë“¤ì„ í†µì§¸ë¡œ ì œê±°
    major_navigation_blocks = [
        r'\*\*QUICK MENU\*\*.*?(?=##|\n\n\*\*|$)',  # í€µë©”ë‰´ ì „ì²´ ë¸”ë¡
        r'\*\*ì¸ê¸°ë©”ë‰´\*\*.*?(?=##|\*\*kt|\n\n|$)',  # ì¸ê¸°ë©”ë‰´ ë¸”ë¡
        r'\*\*!\[kt.*?(?=##|^\*\s|$)',  # KT ë„¤ë¹„ê²Œì´ì…˜ ë©”ë‰´ ì „ì²´
        r'^\*\s+Shop.*?(?=##|^\*[^*]|$)',  # Shop ë©”ë‰´ ì „ì²´ ì„¹ì…˜
        r'^\*\s+ìƒí’ˆ.*?(?=##|^\*[^*]|$)',  # ìƒí’ˆ ë©”ë‰´ ì „ì²´ ì„¹ì…˜  
        r'^\*\s+ë¡œë°.*?(?=##|^\*[^*]|$)',  # ë¡œë° ë©”ë‰´ ì „ì²´ ì„¹ì…˜
        r'Family Site.*?$',  # Family Site ì„¹ì…˜
        r'\[ê·¸ë£¹ì‚¬ ì†Œê°œ\].*?$',  # ê·¸ë£¹ì‚¬ ì†Œê°œ
        r'\(ì£¼\)ì¼€ì´í‹°.*?ë§¨ìœ„ë¡œ ìŠ¤í¬ë¡¤',  # í‘¸í„° ì „ì²´
    ]
    
    for pattern in major_navigation_blocks:
        cleaned = re.sub(pattern, '', cleaned, flags=re.DOTALL | re.MULTILINE | re.IGNORECASE)
    
    # 2. ì„¸ë¶€ ë¶ˆí•„ìš” ìš”ì†Œ ì œê±°
    detailed_patterns = [
        r'ë³¸ë¬¸ ë°”ë¡œê°€ê¸°.*?ë°”ë¡œ ê°€ê¸°',  # ì ‘ê·¼ì„± ë§í¬ë“¤
        r'í‰ì¼ì˜¤ì „.*?ì˜¤í›„\d+ì‹œ',  # ìš´ì˜ì‹œê°„ ì •ë³´ë“¤
        r'\d{4}-\d{4}\s*\(.*?\)',  # ì „í™”ë²ˆí˜¸ íŒ¨í„´
        r'Copyright.*?ALL RIGHTS RESERVED\.?',  # ì €ì‘ê¶Œ ì •ë³´
        r'COPYRIGHTâ“’.*?ALL RIGHTS RESERVED\.?',
        r';?\)$',  # ì¤„ ëì˜ ;) íŒ¨í„´
        r'https?://[^\s)]+\)',  # URLì´ í¬í•¨ëœ ê´„í˜¸ íŒ¨í„´
        r'\([^)]*https?://[^)]*\)',  # ê´„í˜¸ ì•ˆì˜ URLë“¤
    ]
    
    for pattern in detailed_patterns:
        cleaned = re.sub(pattern, '', cleaned, flags=re.MULTILINE | re.IGNORECASE)
    
    # 3. ê¸°ë³¸ í…ìŠ¤íŠ¸ ì •ë¦¬ ì ìš©
    return clean_crawled_text(cleaned)

def get_processing_quality_score(original_text: str, cleaned_text: str) -> float:
    """
    í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬ í’ˆì§ˆ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        original_text: ì›ë³¸ í…ìŠ¤íŠ¸
        cleaned_text: ì •ì œëœ í…ìŠ¤íŠ¸
        
    Returns:
        í’ˆì§ˆ ì ìˆ˜ (0.0 ~ 1.0)
    """
    if not original_text or not cleaned_text:
        return 0.0
    
    # ì •ì œ í›„ í…ìŠ¤íŠ¸ ê¸¸ì´ ë¹„ìœ¨
    length_ratio = len(cleaned_text) / len(original_text)
    
    # ë§ˆí¬ë‹¤ìš´ ë¬¸ë²• ê°ì†Œ ì •ë„
    markdown_before = len(re.findall(r'[#\*\-]{2,}', original_text))
    markdown_after = len(re.findall(r'[#\*\-]{2,}', cleaned_text))
    markdown_reduction = (markdown_before - markdown_after) / max(markdown_before, 1)
    
    # UI ìš”ì†Œ ì œê±° ì •ë„
    ui_before = len(re.findall(r'_[^_]*_|ì•„ì´ì½˜|ë²„íŠ¼', original_text))
    ui_after = len(re.findall(r'_[^_]*_|ì•„ì´ì½˜|ë²„íŠ¼', cleaned_text))
    ui_reduction = (ui_before - ui_after) / max(ui_before, 1)
    
    # ì¢…í•© í’ˆì§ˆ ì ìˆ˜ (ê°€ì¤‘ í‰ê· )
    quality_score = (
        length_ratio * 0.4 +        # ë‚´ìš© ë³´ì¡´ë„
        markdown_reduction * 0.3 +   # ë§ˆí¬ë‹¤ìš´ ì •ë¦¬ë„
        ui_reduction * 0.3          # UI ìš”ì†Œ ì œê±°ë„
    )
    
    return min(max(quality_score, 0.0), 1.0)

def post_process_crawl_result(crawl_result: CrawlResult, clean_text: bool = True) -> CrawlResult:
    """
    í¬ë¡¤ë§ ê²°ê³¼ì— í›„ì²˜ë¦¬ë¥¼ ì ìš©í•©ë‹ˆë‹¤.
    
    Args:
        crawl_result: ì›ë³¸ í¬ë¡¤ë§ ê²°ê³¼
        clean_text: í…ìŠ¤íŠ¸ ì •ì œ ì ìš© ì—¬ë¶€
        
    Returns:
        í›„ì²˜ë¦¬ê°€ ì ìš©ëœ í¬ë¡¤ë§ ê²°ê³¼
    """
    if not clean_text or not crawl_result.text:
        return crawl_result
    
    # ì›ë³¸ í…ìŠ¤íŠ¸ ë³´ì¡´
    original_text = crawl_result.text
    
    # í…ìŠ¤íŠ¸ ì •ì œ
    cleaned_text = extract_main_content(original_text)
    processing_quality = get_processing_quality_score(original_text, cleaned_text)
    
    # ìƒˆë¡œìš´ ë©”íƒ€ë°ì´í„° ìƒì„± (ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ë³´ì¡´)
    new_metadata = crawl_result.metadata.copy()
    new_metadata.update({
        "post_processing_applied": True,
        "original_text_length": len(original_text),
        "processed_text_length": len(cleaned_text),
        "text_reduction_ratio": len(cleaned_text) / len(original_text) if original_text else 1.0,
        "processing_quality_score": processing_quality,
        "processing_timestamp": datetime.now().isoformat()
    })
    
    # í›„ì²˜ë¦¬ëœ ê²°ê³¼ ë°˜í™˜
    return CrawlResult(
        url=crawl_result.url,
        title=crawl_result.title,
        text=cleaned_text,
        hierarchy=crawl_result.hierarchy,
        metadata=new_metadata,
        status=crawl_result.status,
        timestamp=crawl_result.timestamp,
        error=crawl_result.error
    )

def create_processing_options() -> Dict[str, Any]:
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ í›„ì²˜ë¦¬ ì˜µì…˜ë“¤ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    return {
        "clean_text": {
            "description": "ë¶ˆí•„ìš”í•œ UI ìš”ì†Œ, ê³¼ë„í•œ ë§ˆí¬ë‹¤ìš´ ì œê±°",
            "default": True
        },
        "extract_main_content": {
            "description": "ì£¼ìš” ì»¨í…ì¸ ë§Œ ì¶”ì¶œ (ë„¤ë¹„ê²Œì´ì…˜, í‘¸í„° ì œê±°)",
            "default": True
        },
        "preserve_original": {
            "description": "ì›ë³¸ í…ìŠ¤íŠ¸ ë©”íƒ€ë°ì´í„°ì— ë³´ì¡´",
            "default": True
        }
    } 